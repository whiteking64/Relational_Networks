{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Pytorch implementation of \"A simple neural network module for relational reasoning\"\n",
    "Sort-of-CLEVRの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b4e78dc3cd9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCNN_MLP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from model import RN, CNN_MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## オプションを受け取る部分\n",
    "デフォルトは論文に記載されているパラメータ値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch Relational-Network sort-of-CLVR Example')\n",
    "parser.add_argument('--model', type=str, choices=['RN', 'CNN_MLP'], default='RN',\n",
    "                    help='resume from model stored')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--epochs', type=int, default=20, metavar='N',\n",
    "                    help='number of epochs to train (default: 20)')\n",
    "parser.add_argument('--lr', type=float, default=0.0001, metavar='LR',\n",
    "                    help='learning rate (default: 0.0001)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--resume', type=str,\n",
    "                    help='resume from model stored')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  変数の設定\n",
    "argsから受け取った変数に名前をつけて格納"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "if args.model == 'CNN_MLP':\n",
    "    model = CNN_MLP(args)\n",
    "else:\n",
    "    model = RN(args)\n",
    "\n",
    "model_dirs = './model'\n",
    "bs = args.batch_size\n",
    "input_img = torch.FloatTensor(bs, 3, 75, 75) #画像の大きさをテンソル化\n",
    "input_qst = torch.FloatTensor(bs, 11) #input_qstのベクトルをテンソル化\n",
    "label = torch.LongTensor(bs) #長さ64のテンソル，ダミーのテストラベル\n",
    "\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "    input_img = input_img.cuda()\n",
    "    input_qst = input_qst.cuda()\n",
    "    label = label.cuda()\n",
    "\n",
    "# 以下3変数は直後のtensor_dataによって頻繁に変更される\n",
    "input_img = Variable(input_img)\n",
    "input_qst = Variable(input_qst)\n",
    "label = Variable(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配列のテンソル化，変形\n",
    "1. 指定したバッチごとに対してimg, qst, ansからなるデータをテンソル化\n",
    "2. L.57-59の変数を各データが使える形に変形して値を代入（コピー？）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_data(data, i):\n",
    "    img = torch.from_numpy(np.asarray(data[0][bs*i:bs*(i+1)]))\n",
    "    qst = torch.from_numpy(np.asarray(data[1][bs*i:bs*(i+1)]))\n",
    "    ans = torch.from_numpy(np.asarray(data[2][bs*i:bs*(i+1)]))\n",
    "\n",
    "    input_img.data.resize_(img.size()).copy_(img)\n",
    "    input_qst.data.resize_(qst.size()).copy_(qst)\n",
    "    label.data.resize_(ans.size()).copy_(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datasetから各種データを取り出す\n",
    "訓練/テストデータのリストのレコード: (img,qst,ans)  \n",
    "このレコードを要素ごとに分割して，取り出す．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvt_data_axis(data):\n",
    "    img = [e[0] for e in data]\n",
    "    qst = [e[1] for e in data]\n",
    "    ans = [e[2] for e in data]\n",
    "    return (img, qst, ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, rel, norel):\n",
    "    model.train()\n",
    "\n",
    "    if len(rel[0]) != len(norel[0]):\n",
    "        print('Not equal length for relation dataset and non-relation dataset.')\n",
    "        return\n",
    "    \n",
    "    #データセットのシャッフル\n",
    "    random.shuffle(rel)\n",
    "    random.shuffle(norel)\n",
    "    #データセットから要素のタプルを取り出す\n",
    "    rel = cvt_data_axis(rel)\n",
    "    norel = cvt_data_axis(norel)\n",
    "    #バッチ学習\n",
    "    for i in range(len(rel[0]) // bs):\n",
    "        tensor_data(rel, i)\n",
    "        accuracy_rel = model.train_(input_img, input_qst, label)\n",
    "\n",
    "        tensor_data(norel, i)\n",
    "        accuracy_norel = model.train_(input_img, input_qst, label)\n",
    "\n",
    "        if i % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)] Relations accuracy: {:.0f}% | \\\n",
    "                Non-relations accuracy: {:.0f}%'.format(epoch, i * bs * 2, \\\n",
    "                len(rel[0]) * 2, 100. * i * bs/ len(rel[0]), accuracy_rel, accuracy_norel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, rel, norel):\n",
    "    model.eval()\n",
    "    if len(rel[0]) != len(norel[0]):\n",
    "        print('Not equal length for relation dataset and non-relation dataset.')\n",
    "        return\n",
    "\n",
    "    rel = cvt_data_axis(rel)\n",
    "    norel = cvt_data_axis(norel)\n",
    "\n",
    "    accuracy_rels = []\n",
    "    accuracy_norels = []\n",
    "    for i in range(len(rel[0]) // bs):\n",
    "        tensor_data(rel, i)\n",
    "        accuracy_rels.append(model.test_(input_img, input_qst, label))\n",
    "\n",
    "        tensor_data(norel, i)\n",
    "        accuracy_norels.append(model.test_(input_img, input_qst, label))\n",
    "\n",
    "    accuracy_rel = sum(accuracy_rels) / len(accuracy_rels) #全てのバッチを調べて，その平均を出している\n",
    "    accuracy_norel = sum(accuracy_norels) / len(accuracy_norels)\n",
    "    print('\\n Test set: Relation accuracy: {:.0f}% | Non-relation accuracy: {:.0f}%\\n'.format(\n",
    "        accuracy_rel, accuracy_norel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データロード\n",
    "gen_dataset.pyで保存したpickleファイルから読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    print('loading data...')\n",
    "    dirs = './data'\n",
    "    filename = os.path.join(dirs, 'sort-of-clevr.pickle')\n",
    "    with open(filename, 'rb') as f:\n",
    "        train_datasets, test_datasets = pickle.load(f)\n",
    "    rel_train = []\n",
    "    rel_test = []\n",
    "    norel_train = []\n",
    "    norel_test = []\n",
    "    print('processing data...')\n",
    "\n",
    "    for img, relations, norelations in train_datasets:\n",
    "        #channel(RGB)方向の次元を3にするためgen_dataset.pyのimgの生成法と関連\n",
    "        img = np.swapaxes(img, 0, 2)\n",
    "        for qst, ans in zip(relations[0], relations[1]):\n",
    "            rel_train.append((img, qst, ans))\n",
    "        for qst, ans in zip(norelations[0], norelations[1]):\n",
    "            norel_train.append((img, qst, ans))\n",
    "\n",
    "    for img, relations, norelations in test_datasets:\n",
    "        img = np.swapaxes(img, 0, 2)\n",
    "        for qst, ans in zip(relations[0], relations[1]):\n",
    "            rel_test.append((img, qst, ans))\n",
    "        for qst, ans in zip(norelations[0], norelations[1]):\n",
    "            norel_test.append((img, qst, ans))\n",
    "\n",
    "    return (rel_train, rel_test, norel_train, norel_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの分割\n",
    "訓練用，テスト用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_train, rel_test, norel_train, norel_test = load_data()\n",
    "try:\n",
    "    os.makedirs(model_dirs)\n",
    "except:\n",
    "    print('directory {} already exists'.format(model_dirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.resume:\n",
    "    filename = os.path.join(model_dirs, args.resume)\n",
    "    if os.path.isfile(filename):\n",
    "        print('==> loading checkpoint {}'.format(filename))\n",
    "        checkpoint = torch.load(filename)\n",
    "        model.load_state_dict(checkpoint)\n",
    "        print('==> loaded checkpoint {}'.format(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習，テスト\n",
    "一定間隔でコマンドラインに出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch, rel_train, norel_train)\n",
    "    print('')\n",
    "    test(epoch, rel_test, norel_test)\n",
    "    model.save_model(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
